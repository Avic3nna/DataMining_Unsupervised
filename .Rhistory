sigma3[2,3]<-t(tau3)%*%((no_label_data[,2]-mu_3D[[3]][2])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
sigma3[3,1]<-sigma3[1,3]
sigma3[3,2]<-sigma3[2,3]
sigma3[3,3]<-t(tau3)%*%((no_label_data[,3]-mu_3D[[3]][3])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
#recompute fourth cov. matrino_label_data
sigma4[1,1]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,1]-mu_3D[[4]][1]))/(mySum(tau4)) #recalculating covariance matrino_label_data
sigma4[1,2]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,2]-mu_3D[[4]][2]))/(mySum(tau4))
sigma4[1,3]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
sigma4[2,1]<-sigma4[1,2]
sigma4[2,2]<-t(tau4)%*%((no_label_data[,2]-mu_3D[[4]][2])*(no_label_data[,2]-mu_3D[[4]][2]))/(mySum(tau4))
sigma4[2,3]<-t(tau4)%*%((no_label_data[,2]-mu_3D[[4]][2])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
sigma4[3,1]<-sigma4[1,3]
sigma4[3,2]<-sigma4[2,3]
sigma4[3,3]<-t(tau4)%*%((no_label_data[,3]-mu_3D[[4]][3])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
#dev.off() #new graph plot
scatter3d(no_label_data[,1], no_label_data[,2], no_label_data[,3], groups=factor(classes), surface = FALSE)
if(dev.cur() > 1) { par(new=TRUE) }
points3d(mu_3D[[1]][1], mu_3D[[1]][2], mu_3D[[1]][3], pch=18, cex=1, col="blue")
points3d(mu_3D[[2]][1], mu_3D[[2]][2], mu_3D[[2]][3], pch=18, cex=1, col="green")
points3d(mu_3D[[3]][1], mu_3D[[3]][2], mu_3D[[3]][3], pch=18, cex=1, col="red")
points3d(mu_3D[[4]][1], mu_3D[[4]][2], mu_3D[[4]][3], pch=18, cex=1, col="purple")
plot3d(ellipse3d(sigma1, centre = mu_3D[[1]]), col = "green", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma2, centre = mu_3D[[2]]), col = "orange", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma3, centre = mu_3D[[3]]), col = "purple", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma4, centre = mu_3D[[4]]), col = "red", alpha = 0.5, add = TRUE)
#new loglik calculation
loglik[k+1]<-mySum(pi1*(log(pi1)+log(matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1),nrow=4,ncol=200))))+
mySum(pi2*(log(pi2)+log(matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2),nrow=4,ncol=200)))) +
mySum(pi3*(log(pi3)+log(matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3),nrow=4,ncol=200)))) +
mySum(pi4*(log(pi4)+log(matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4),nrow=4,ncol=200))))
k<-k+1
}
# Comparison with library implementation of EM
# library(mixtools)
# gm<-mvnormalmixEM(x,k=2,epsilon=1e-04)  #multivariate normal distribution EM
#                                         #normalmixEM is only for univariate normal
# gm$lambda
# gm$mu
# gm$sigma
# gm$loglik
# plot(gm, which=2)
#
# (head(gm$posterior))
# pred<-apply(gm$posterior, 1, function(row) which.max(row))
# (confusionMatrix[1,1]+confusionMatrix[2,2])/1000 # accuracy
# (confusionMatrix[1,2]+confusionMatrix[2,1])/1000 # error rate
# Implementation of EM algorithm
# clear everything and load required libraries/codes
rm(list=ls())
library(mvtnorm)
library(car)
library(scales)
#source("C:/Users/Sven/Google Drive/Teaching/Data_Mining_2020/Lab3/mySum.R")
root_path = "G:/My Drive/1. EIT Digital master/Estland/Semester 1/Data mining/data-mining-iti8730"
#loading and plotting data
#setwd("C:/Users/Sven/Google Drive/Teaching/Data_Mining_2020/Lab3/Data")
setwd(root_path)
source("./practice_3/mySum.R")
#load("2dData-strange.RData")
#load("C:/Users/Sven/Google Drive/Teaching/Data_Mining_2020/Lab3/Data/2gaussiandata.RData")
load("./Own functions/data/3Dgauss.RData")
library(rgl) #interactive 3D plot
scatter3d(generated_data[,1], generated_data[,2], generated_data[,3], groups=factor(generated_data[,ncol(generated_data)]), surface = FALSE)
# data manipulation
classes <- generated_data[,4] #labels vector
no_label_data <-generated_data[,1:3] #removing labels from data
hist(no_label_data, col="blue")
plot(density(no_label_data))
#Step 1: initialization
pi1<- 1.5  # 0.5
pi2<- 0.5
pi3<- 3
pi4<- 2
#initial values for means
mu_3D = list(c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1)),  #mu1
c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1)), #mu2
c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1)), #mu3
c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1))) #mu4
#...
#random samples per matrix
# xy = sample(1:10, 1)
# xz = sample(1:10, 1)
# yz = sample(1:10, 1)
# x = sample(1:5, 1)
# y = sample(1:5, 1)
# z = sample(1:5, 1)
#
# xy1 = sample(1:10, 1)
# xz1 = sample(1:10, 1)
# yz1 = sample(1:10, 1)
# x1 = sample(1:5, 1)
# y1 = sample(1:5, 1)
# z1 = sample(1:5, 1)
#
# xy2 = sample(1:10, 1)
# xz2 = sample(1:10, 1)
# yz2 = sample(1:10, 1)
# x2 = sample(1:5, 1)
# y2 = sample(1:5, 1)
# z2 = sample(1:5, 1)
#
# xy3 = sample(1:10, 1)
# xz3 = sample(1:10, 1)
# yz3 = sample(1:10, 1)
# x3 = sample(1:5, 1)
# y3 = sample(1:5, 1)
# z3 = sample(1:5, 1)
xy = runif(1)
xz = runif(1)
yz = runif(1)
x = runif(1)
y = runif(1)
z = runif(1)
xy1 = runif(1)
xz1 = runif(1)
yz1 = runif(1)
x1 = runif(1)
y1 = runif(1)
z1 = runif(1)
xy2 = runif(1)
xz2 = runif(1)
yz2 = runif(1)
x2 = runif(1)
y2 = runif(1)
z2 = runif(1)
xy3 = runif(1)
xz3 = runif(1)
yz3 = runif(1)
x3 = runif(1)
y3 = runif(1)
z3 = runif(1)
#  covar  x xy xz
#         xy y yz
#         xz yz z
eig_vec_1 = matrix(c(x, xy,  xz,  xy, y,  yz,  xz,  yz,  z), ncol=length(mu_3D[[1]]))
eig_vec_2 = matrix(c(x1,xy1, xz1, xy1,y1, yz1, xz1, yz1, z1),ncol=length(mu_3D[[1]]))
eig_vec_3 = matrix(c(x2,xy2, xz2, xy2,y2, yz2, xz2, yz2, z2),ncol=length(mu_3D[[1]]))
eig_vec_4 = matrix(c(x3,xy3, xz3, xy3,y3, yz3, xz3, yz3, z3),ncol=length(mu_3D[[1]]))
eig_val_1 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
eig_val_2 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
eig_val_3 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
eig_val_4 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
# #needs to be positive semi-definite
# covar = list(matrix(c(x, xy,  xz,  xy, y,  yz,  xz,  yz,  z), ncol=length(mu_3D[[1]])),  #sigma1
#              matrix(c(x1,xy1, xz1, xy1,y1, yz1, xz1, yz1, z1),ncol=length(mu_3D[[1]])),  #sigma2
#              matrix(c(x2,xy2, xz2, xy2,y2, yz2, xz2, yz2, z2),ncol=length(mu_3D[[1]])),  #sigma3
#              matrix(c(x3,xy3, xz3, xy3,y3, yz3, xz3, yz3, z3),ncol=length(mu_3D[[1]])))  #sigma4
#...
#covariance matrices
sigma1 <- eig_vec_1 %*% eig_val_1 %*% t(eig_vec_1)
sigma2 <-  eig_vec_2 %*% eig_val_2 %*% t(eig_vec_2)
sigma3 <-  eig_vec_3 %*% eig_val_3 %*% t(eig_vec_3)
sigma4 <-  eig_vec_4 %*% eig_val_4 %*% t(eig_vec_4)
#Plotting initizations in the data set
scatter3d(no_label_data[,1], no_label_data[,2], no_label_data[,3], groups=factor(classes), surface = FALSE)
par(new=TRUE) #to include the previous plot on the previous = combine plots
points3d(mu_3D[[1]][1], mu_3D[[1]][2], mu_3D[[1]][3], pch=18, cex=1, col="blue")
points3d(mu_3D[[2]][1], mu_3D[[2]][2], mu_3D[[2]][3], pch=18, cex=1, col="green")
points3d(mu_3D[[3]][1], mu_3D[[3]][2], mu_3D[[3]][3], pch=18, cex=1, col="red")
points3d(mu_3D[[4]][1], mu_3D[[4]][2], mu_3D[[4]][3], pch=18, cex=1, col="purple")
plot3d(ellipse3d(sigma1, centre = mu_3D[[1]]), col = "green", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma2, centre = mu_3D[[2]]), col = "orange", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma3, centre = mu_3D[[3]]), col = "purple", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma4, centre = mu_3D[[4]]), col = "red", alpha = 0.5, add = TRUE)
#library(generalCorr)
#minor(x, row, column)
#initial conditions for stopping the algo
loglik<- rep(NA, 2000) #log likelihoods storage
loglik[1]<-0 #initial log likelihood value
loglik[2]<-mySum(pi1*(log(pi1)+log(matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1),nrow=4,ncol=200))))+
mySum(pi2*(log(pi2)+log(matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2),nrow=4,ncol=200)))) +
mySum(pi3*(log(pi3)+log(matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3),nrow=4,ncol=200)))) +
mySum(pi4*(log(pi4)+log(matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4),nrow=4,ncol=200))))
k<-2
#main loop with step 2, 3 - EM
while(abs(loglik[k]-loglik[k-1]) >= 1e-6) {  #if no significant improvement, finish
# Step 2 -> E-step: Expectation - Calculating the "Soft Labels" of Each Data Point
tau1<-pi1*matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1))
tau2<-pi2*matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2))
tau3<-pi3*matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3))
tau4<-pi4*matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4))
normalizer<-tau1 + tau2 + tau3 + tau4
tau1<-tau1/normalizer
tau2<-tau2/normalizer
tau3<-tau3/normalizer
tau4<-tau4/normalizer
# Step 3 -> M step: Maximization - Re-estimate the Component Parameters
n<-dim(no_label_data)[1] #number of datapoints
pi1<-mySum(tau1)/n #recomputing responsabilities
pi2<-mySum(tau2)/n
pi3<-mySum(tau3)/n
pi4<-mySum(tau4)/n
mu_3D[[1]][1]<-(t(tau1)%*%no_label_data[,1])/mySum(tau1) #recalculating mean values
mu_3D[[1]][2]<-(t(tau1)%*%no_label_data[,2])/mySum(tau1)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[1]][3]<-(t(tau1)%*%no_label_data[,3])/mySum(tau1)
mu_3D[[2]][1]<-(t(tau2)%*%no_label_data[,1])/mySum(tau2) #recalculating mean values
mu_3D[[2]][2]<-(t(tau2)%*%no_label_data[,2])/mySum(tau2)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[2]][3]<-(t(tau2)%*%no_label_data[,3])/mySum(tau2)
mu_3D[[3]][1]<-(t(tau3)%*%no_label_data[,1])/mySum(tau3) #recalculating mean values
mu_3D[[3]][2]<-(t(tau3)%*%no_label_data[,2])/mySum(tau3)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[3]][3]<-(t(tau3)%*%no_label_data[,3])/mySum(tau3)
mu_3D[[4]][1]<-(t(tau4)%*%no_label_data[,1])/mySum(tau4) #recalculating mean values
mu_3D[[4]][2]<-(t(tau4)%*%no_label_data[,2])/mySum(tau4)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[4]][3]<-(t(tau4)%*%no_label_data[,3])/mySum(tau4)
#  covar  x xy xz
#         xy y yz
#         xz yz z
#recompute first cov. matrix
sigma1[1,1]<-t(tau1)%*%((no_label_data[,1]-mu_3D[[1]][1])*(no_label_data[,1]-mu_3D[[1]][1]))/(mySum(tau1)) #recalculating covariance matrino_label_data
sigma1[1,2]<-t(tau1)%*%((no_label_data[,1]-mu_3D[[1]][1])*(no_label_data[,2]-mu_3D[[1]][2]))/(mySum(tau1))
sigma1[1,3]<-t(tau1)%*%((no_label_data[,1]-mu_3D[[1]][1])*(no_label_data[,3]-mu_3D[[1]][3]))/(mySum(tau1))
sigma1[2,1]<-sigma1[1,2]
sigma1[2,2]<-t(tau1)%*%((no_label_data[,2]-mu_3D[[1]][2])*(no_label_data[,2]-mu_3D[[1]][2]))/(mySum(tau1))
sigma1[2,3]<-t(tau1)%*%((no_label_data[,2]-mu_3D[[1]][2])*(no_label_data[,3]-mu_3D[[1]][3]))/(mySum(tau1))
sigma1[3,1]<-sigma1[1,3]
sigma1[3,2]<-sigma1[2,3]
sigma1[3,3]<-t(tau1)%*%((no_label_data[,3]-mu_3D[[1]][3])*(no_label_data[,3]-mu_3D[[1]][3]))/(mySum(tau1))
#recompute second cov. matrino_label_data
sigma2[1,1]<-t(tau2)%*%((no_label_data[,1]-mu_3D[[2]][1])*(no_label_data[,1]-mu_3D[[2]][1]))/(mySum(tau2)) #recalculating covariance matrino_label_data
sigma2[1,2]<-t(tau2)%*%((no_label_data[,1]-mu_3D[[2]][1])*(no_label_data[,2]-mu_3D[[2]][2]))/(mySum(tau2))
sigma2[1,3]<-t(tau2)%*%((no_label_data[,1]-mu_3D[[2]][1])*(no_label_data[,3]-mu_3D[[2]][3]))/(mySum(tau2))
sigma2[2,1]<-sigma2[1,2]
sigma2[2,2]<-t(tau2)%*%((no_label_data[,2]-mu_3D[[2]][2])*(no_label_data[,2]-mu_3D[[2]][2]))/(mySum(tau2))
sigma2[2,3]<-t(tau2)%*%((no_label_data[,2]-mu_3D[[2]][2])*(no_label_data[,3]-mu_3D[[2]][3]))/(mySum(tau2))
sigma2[3,1]<-sigma2[1,3]
sigma2[3,2]<-sigma2[2,3]
sigma2[3,3]<-t(tau2)%*%((no_label_data[,3]-mu_3D[[2]][3])*(no_label_data[,3]-mu_3D[[2]][3]))/(mySum(tau2))
#recompute third cov. matrino_label_data
sigma3[1,1]<-t(tau3)%*%((no_label_data[,1]-mu_3D[[3]][1])*(no_label_data[,1]-mu_3D[[3]][1]))/(mySum(tau3)) #recalculating covariance matrino_label_data
sigma3[1,2]<-t(tau3)%*%((no_label_data[,1]-mu_3D[[3]][1])*(no_label_data[,2]-mu_3D[[3]][2]))/(mySum(tau3))
sigma3[1,3]<-t(tau3)%*%((no_label_data[,1]-mu_3D[[3]][1])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
sigma3[2,1]<-sigma3[1,2]
sigma3[2,2]<-t(tau3)%*%((no_label_data[,2]-mu_3D[[3]][2])*(no_label_data[,2]-mu_3D[[3]][2]))/(mySum(tau3))
sigma3[2,3]<-t(tau3)%*%((no_label_data[,2]-mu_3D[[3]][2])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
sigma3[3,1]<-sigma3[1,3]
sigma3[3,2]<-sigma3[2,3]
sigma3[3,3]<-t(tau3)%*%((no_label_data[,3]-mu_3D[[3]][3])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
#recompute fourth cov. matrino_label_data
sigma4[1,1]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,1]-mu_3D[[4]][1]))/(mySum(tau4)) #recalculating covariance matrino_label_data
sigma4[1,2]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,2]-mu_3D[[4]][2]))/(mySum(tau4))
sigma4[1,3]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
sigma4[2,1]<-sigma4[1,2]
sigma4[2,2]<-t(tau4)%*%((no_label_data[,2]-mu_3D[[4]][2])*(no_label_data[,2]-mu_3D[[4]][2]))/(mySum(tau4))
sigma4[2,3]<-t(tau4)%*%((no_label_data[,2]-mu_3D[[4]][2])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
sigma4[3,1]<-sigma4[1,3]
sigma4[3,2]<-sigma4[2,3]
sigma4[3,3]<-t(tau4)%*%((no_label_data[,3]-mu_3D[[4]][3])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
#dev.off() #new graph plot
scatter3d(no_label_data[,1], no_label_data[,2], no_label_data[,3], groups=factor(classes), surface = FALSE)
if(dev.cur() > 1) { par(new=TRUE) }
points3d(mu_3D[[1]][1], mu_3D[[1]][2], mu_3D[[1]][3], pch=18, cex=1, col="blue")
points3d(mu_3D[[2]][1], mu_3D[[2]][2], mu_3D[[2]][3], pch=18, cex=1, col="green")
points3d(mu_3D[[3]][1], mu_3D[[3]][2], mu_3D[[3]][3], pch=18, cex=1, col="red")
points3d(mu_3D[[4]][1], mu_3D[[4]][2], mu_3D[[4]][3], pch=18, cex=1, col="purple")
plot3d(ellipse3d(sigma1, centre = mu_3D[[1]]), col = "green")
plot3d(ellipse3d(sigma2, centre = mu_3D[[2]]), col = "orange")
plot3d(ellipse3d(sigma3, centre = mu_3D[[3]]), col = "purple")
plot3d(ellipse3d(sigma4, centre = mu_3D[[4]]), col = "red")
#new loglik calculation
loglik[k+1]<-mySum(pi1*(log(pi1)+log(matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1),nrow=4,ncol=200))))+
mySum(pi2*(log(pi2)+log(matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2),nrow=4,ncol=200)))) +
mySum(pi3*(log(pi3)+log(matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3),nrow=4,ncol=200)))) +
mySum(pi4*(log(pi4)+log(matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4),nrow=4,ncol=200))))
k<-k+1
}
# Comparison with library implementation of EM
# library(mixtools)
# gm<-mvnormalmixEM(x,k=2,epsilon=1e-04)  #multivariate normal distribution EM
#                                         #normalmixEM is only for univariate normal
# gm$lambda
# gm$mu
# gm$sigma
# gm$loglik
# plot(gm, which=2)
#
# (head(gm$posterior))
# pred<-apply(gm$posterior, 1, function(row) which.max(row))
# (confusionMatrix[1,1]+confusionMatrix[2,2])/1000 # accuracy
# (confusionMatrix[1,2]+confusionMatrix[2,1])/1000 # error rate
# Implementation of EM algorithm
# clear everything and load required libraries/codes
rm(list=ls())
library(mvtnorm)
library(car)
library(scales)
#source("C:/Users/Sven/Google Drive/Teaching/Data_Mining_2020/Lab3/mySum.R")
root_path = "G:/My Drive/1. EIT Digital master/Estland/Semester 1/Data mining/data-mining-iti8730"
#loading and plotting data
#setwd("C:/Users/Sven/Google Drive/Teaching/Data_Mining_2020/Lab3/Data")
setwd(root_path)
source("./practice_3/mySum.R")
#load("2dData-strange.RData")
#load("C:/Users/Sven/Google Drive/Teaching/Data_Mining_2020/Lab3/Data/2gaussiandata.RData")
load("./Own functions/data/3Dgauss.RData")
library(rgl) #interactive 3D plot
scatter3d(generated_data[,1], generated_data[,2], generated_data[,3], groups=factor(generated_data[,ncol(generated_data)]), surface = FALSE)
# data manipulation
classes <- generated_data[,4] #labels vector
no_label_data <-generated_data[,1:3] #removing labels from data
hist(no_label_data, col="blue")
plot(density(no_label_data))
#Step 1: initialization
pi1<- 1.5  # 0.5
pi2<- 0.5
pi3<- 3
pi4<- 2
#initial values for means
mu_3D = list(c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1)),  #mu1
c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1)), #mu2
c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1)), #mu3
c(sample(-4:4, 1), sample(-4:4, 1), sample(-4:4, 1))) #mu4
#...
#random samples per matrix
# xy = sample(1:10, 1)
# xz = sample(1:10, 1)
# yz = sample(1:10, 1)
# x = sample(1:5, 1)
# y = sample(1:5, 1)
# z = sample(1:5, 1)
#
# xy1 = sample(1:10, 1)
# xz1 = sample(1:10, 1)
# yz1 = sample(1:10, 1)
# x1 = sample(1:5, 1)
# y1 = sample(1:5, 1)
# z1 = sample(1:5, 1)
#
# xy2 = sample(1:10, 1)
# xz2 = sample(1:10, 1)
# yz2 = sample(1:10, 1)
# x2 = sample(1:5, 1)
# y2 = sample(1:5, 1)
# z2 = sample(1:5, 1)
#
# xy3 = sample(1:10, 1)
# xz3 = sample(1:10, 1)
# yz3 = sample(1:10, 1)
# x3 = sample(1:5, 1)
# y3 = sample(1:5, 1)
# z3 = sample(1:5, 1)
xy = runif(1)
xz = runif(1)
yz = runif(1)
x = runif(1)
y = runif(1)
z = runif(1)
xy1 = runif(1)
xz1 = runif(1)
yz1 = runif(1)
x1 = runif(1)
y1 = runif(1)
z1 = runif(1)
xy2 = runif(1)
xz2 = runif(1)
yz2 = runif(1)
x2 = runif(1)
y2 = runif(1)
z2 = runif(1)
xy3 = runif(1)
xz3 = runif(1)
yz3 = runif(1)
x3 = runif(1)
y3 = runif(1)
z3 = runif(1)
#  covar  x xy xz
#         xy y yz
#         xz yz z
eig_vec_1 = matrix(c(x, xy,  xz,  xy, y,  yz,  xz,  yz,  z), ncol=length(mu_3D[[1]]))
eig_vec_2 = matrix(c(x1,xy1, xz1, xy1,y1, yz1, xz1, yz1, z1),ncol=length(mu_3D[[1]]))
eig_vec_3 = matrix(c(x2,xy2, xz2, xy2,y2, yz2, xz2, yz2, z2),ncol=length(mu_3D[[1]]))
eig_vec_4 = matrix(c(x3,xy3, xz3, xy3,y3, yz3, xz3, yz3, z3),ncol=length(mu_3D[[1]]))
eig_val_1 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
eig_val_2 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
eig_val_3 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
eig_val_4 = matrix(c(1,0,0,0,1,0,0,0,1), nrow=length(mu_3D[[1]]))
# #needs to be positive semi-definite
# covar = list(matrix(c(x, xy,  xz,  xy, y,  yz,  xz,  yz,  z), ncol=length(mu_3D[[1]])),  #sigma1
#              matrix(c(x1,xy1, xz1, xy1,y1, yz1, xz1, yz1, z1),ncol=length(mu_3D[[1]])),  #sigma2
#              matrix(c(x2,xy2, xz2, xy2,y2, yz2, xz2, yz2, z2),ncol=length(mu_3D[[1]])),  #sigma3
#              matrix(c(x3,xy3, xz3, xy3,y3, yz3, xz3, yz3, z3),ncol=length(mu_3D[[1]])))  #sigma4
#...
#covariance matrices
sigma1 <- eig_vec_1 %*% eig_val_1 %*% t(eig_vec_1)
sigma2 <-  eig_vec_2 %*% eig_val_2 %*% t(eig_vec_2)
sigma3 <-  eig_vec_3 %*% eig_val_3 %*% t(eig_vec_3)
sigma4 <-  eig_vec_4 %*% eig_val_4 %*% t(eig_vec_4)
#Plotting initizations in the data set
scatter3d(no_label_data[,1], no_label_data[,2], no_label_data[,3], groups=factor(classes), surface = FALSE)
par(new=TRUE) #to include the previous plot on the previous = combine plots
points3d(mu_3D[[1]][1], mu_3D[[1]][2], mu_3D[[1]][3], pch=18, cex=1, col="blue")
points3d(mu_3D[[2]][1], mu_3D[[2]][2], mu_3D[[2]][3], pch=18, cex=1, col="green")
points3d(mu_3D[[3]][1], mu_3D[[3]][2], mu_3D[[3]][3], pch=18, cex=1, col="red")
points3d(mu_3D[[4]][1], mu_3D[[4]][2], mu_3D[[4]][3], pch=18, cex=1, col="purple")
plot3d(ellipse3d(sigma1, centre = mu_3D[[1]]), col = "green", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma2, centre = mu_3D[[2]]), col = "orange", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma3, centre = mu_3D[[3]]), col = "purple", alpha = 0.5, add = TRUE)
plot3d(ellipse3d(sigma4, centre = mu_3D[[4]]), col = "red", alpha = 0.5, add = TRUE)
#library(generalCorr)
#minor(x, row, column)
#initial conditions for stopping the algo
loglik<- rep(NA, 2000) #log likelihoods storage
loglik[1]<-0 #initial log likelihood value
loglik[2]<-mySum(pi1*(log(pi1)+log(matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1),nrow=4,ncol=200))))+
mySum(pi2*(log(pi2)+log(matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2),nrow=4,ncol=200)))) +
mySum(pi3*(log(pi3)+log(matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3),nrow=4,ncol=200)))) +
mySum(pi4*(log(pi4)+log(matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4),nrow=4,ncol=200))))
k<-2
#main loop with step 2, 3 - EM
while(abs(loglik[k]-loglik[k-1]) >= 1e-6) {  #if no significant improvement, finish
# Step 2 -> E-step: Expectation - Calculating the "Soft Labels" of Each Data Point
tau1<-pi1*matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1))
tau2<-pi2*matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2))
tau3<-pi3*matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3))
tau4<-pi4*matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4))
normalizer<-tau1 + tau2 + tau3 + tau4
tau1<-tau1/normalizer
tau2<-tau2/normalizer
tau3<-tau3/normalizer
tau4<-tau4/normalizer
# Step 3 -> M step: Maximization - Re-estimate the Component Parameters
n<-dim(no_label_data)[1] #number of datapoints
pi1<-mySum(tau1)/n #recomputing responsabilities
pi2<-mySum(tau2)/n
pi3<-mySum(tau3)/n
pi4<-mySum(tau4)/n
mu_3D[[1]][1]<-(t(tau1)%*%no_label_data[,1])/mySum(tau1) #recalculating mean values
mu_3D[[1]][2]<-(t(tau1)%*%no_label_data[,2])/mySum(tau1)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[1]][3]<-(t(tau1)%*%no_label_data[,3])/mySum(tau1)
mu_3D[[2]][1]<-(t(tau2)%*%no_label_data[,1])/mySum(tau2) #recalculating mean values
mu_3D[[2]][2]<-(t(tau2)%*%no_label_data[,2])/mySum(tau2)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[2]][3]<-(t(tau2)%*%no_label_data[,3])/mySum(tau2)
mu_3D[[3]][1]<-(t(tau3)%*%no_label_data[,1])/mySum(tau3) #recalculating mean values
mu_3D[[3]][2]<-(t(tau3)%*%no_label_data[,2])/mySum(tau3)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[3]][3]<-(t(tau3)%*%no_label_data[,3])/mySum(tau3)
mu_3D[[4]][1]<-(t(tau4)%*%no_label_data[,1])/mySum(tau4) #recalculating mean values
mu_3D[[4]][2]<-(t(tau4)%*%no_label_data[,2])/mySum(tau4)  #t(tau) to perform matrix multiplication, row by vector == scalar
mu_3D[[4]][3]<-(t(tau4)%*%no_label_data[,3])/mySum(tau4)
#  covar  x xy xz
#         xy y yz
#         xz yz z
#recompute first cov. matrix
sigma1[1,1]<-t(tau1)%*%((no_label_data[,1]-mu_3D[[1]][1])*(no_label_data[,1]-mu_3D[[1]][1]))/(mySum(tau1)) #recalculating covariance matrino_label_data
sigma1[1,2]<-t(tau1)%*%((no_label_data[,1]-mu_3D[[1]][1])*(no_label_data[,2]-mu_3D[[1]][2]))/(mySum(tau1))
sigma1[1,3]<-t(tau1)%*%((no_label_data[,1]-mu_3D[[1]][1])*(no_label_data[,3]-mu_3D[[1]][3]))/(mySum(tau1))
sigma1[2,1]<-sigma1[1,2]
sigma1[2,2]<-t(tau1)%*%((no_label_data[,2]-mu_3D[[1]][2])*(no_label_data[,2]-mu_3D[[1]][2]))/(mySum(tau1))
sigma1[2,3]<-t(tau1)%*%((no_label_data[,2]-mu_3D[[1]][2])*(no_label_data[,3]-mu_3D[[1]][3]))/(mySum(tau1))
sigma1[3,1]<-sigma1[1,3]
sigma1[3,2]<-sigma1[2,3]
sigma1[3,3]<-t(tau1)%*%((no_label_data[,3]-mu_3D[[1]][3])*(no_label_data[,3]-mu_3D[[1]][3]))/(mySum(tau1))
#recompute second cov. matrino_label_data
sigma2[1,1]<-t(tau2)%*%((no_label_data[,1]-mu_3D[[2]][1])*(no_label_data[,1]-mu_3D[[2]][1]))/(mySum(tau2)) #recalculating covariance matrino_label_data
sigma2[1,2]<-t(tau2)%*%((no_label_data[,1]-mu_3D[[2]][1])*(no_label_data[,2]-mu_3D[[2]][2]))/(mySum(tau2))
sigma2[1,3]<-t(tau2)%*%((no_label_data[,1]-mu_3D[[2]][1])*(no_label_data[,3]-mu_3D[[2]][3]))/(mySum(tau2))
sigma2[2,1]<-sigma2[1,2]
sigma2[2,2]<-t(tau2)%*%((no_label_data[,2]-mu_3D[[2]][2])*(no_label_data[,2]-mu_3D[[2]][2]))/(mySum(tau2))
sigma2[2,3]<-t(tau2)%*%((no_label_data[,2]-mu_3D[[2]][2])*(no_label_data[,3]-mu_3D[[2]][3]))/(mySum(tau2))
sigma2[3,1]<-sigma2[1,3]
sigma2[3,2]<-sigma2[2,3]
sigma2[3,3]<-t(tau2)%*%((no_label_data[,3]-mu_3D[[2]][3])*(no_label_data[,3]-mu_3D[[2]][3]))/(mySum(tau2))
#recompute third cov. matrino_label_data
sigma3[1,1]<-t(tau3)%*%((no_label_data[,1]-mu_3D[[3]][1])*(no_label_data[,1]-mu_3D[[3]][1]))/(mySum(tau3)) #recalculating covariance matrino_label_data
sigma3[1,2]<-t(tau3)%*%((no_label_data[,1]-mu_3D[[3]][1])*(no_label_data[,2]-mu_3D[[3]][2]))/(mySum(tau3))
sigma3[1,3]<-t(tau3)%*%((no_label_data[,1]-mu_3D[[3]][1])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
sigma3[2,1]<-sigma3[1,2]
sigma3[2,2]<-t(tau3)%*%((no_label_data[,2]-mu_3D[[3]][2])*(no_label_data[,2]-mu_3D[[3]][2]))/(mySum(tau3))
sigma3[2,3]<-t(tau3)%*%((no_label_data[,2]-mu_3D[[3]][2])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
sigma3[3,1]<-sigma3[1,3]
sigma3[3,2]<-sigma3[2,3]
sigma3[3,3]<-t(tau3)%*%((no_label_data[,3]-mu_3D[[3]][3])*(no_label_data[,3]-mu_3D[[3]][3]))/(mySum(tau3))
#recompute fourth cov. matrino_label_data
sigma4[1,1]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,1]-mu_3D[[4]][1]))/(mySum(tau4)) #recalculating covariance matrino_label_data
sigma4[1,2]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,2]-mu_3D[[4]][2]))/(mySum(tau4))
sigma4[1,3]<-t(tau4)%*%((no_label_data[,1]-mu_3D[[4]][1])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
sigma4[2,1]<-sigma4[1,2]
sigma4[2,2]<-t(tau4)%*%((no_label_data[,2]-mu_3D[[4]][2])*(no_label_data[,2]-mu_3D[[4]][2]))/(mySum(tau4))
sigma4[2,3]<-t(tau4)%*%((no_label_data[,2]-mu_3D[[4]][2])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
sigma4[3,1]<-sigma4[1,3]
sigma4[3,2]<-sigma4[2,3]
sigma4[3,3]<-t(tau4)%*%((no_label_data[,3]-mu_3D[[4]][3])*(no_label_data[,3]-mu_3D[[4]][3]))/(mySum(tau4))
#dev.off() #new graph plot
#scatter3d(no_label_data[,1], no_label_data[,2], no_label_data[,3], groups=factor(classes), surface = FALSE)
if(dev.cur() > 1) { par(new=TRUE) }
points3d(mu_3D[[1]][1], mu_3D[[1]][2], mu_3D[[1]][3], pch=18, cex=1, col="blue")
points3d(mu_3D[[2]][1], mu_3D[[2]][2], mu_3D[[2]][3], pch=18, cex=1, col="green")
points3d(mu_3D[[3]][1], mu_3D[[3]][2], mu_3D[[3]][3], pch=18, cex=1, col="red")
points3d(mu_3D[[4]][1], mu_3D[[4]][2], mu_3D[[4]][3], pch=18, cex=1, col="purple")
plot3d(ellipse3d(sigma1, centre = mu_3D[[1]]), col = "green")
plot3d(ellipse3d(sigma2, centre = mu_3D[[2]]), col = "orange")
plot3d(ellipse3d(sigma3, centre = mu_3D[[3]]), col = "purple")
plot3d(ellipse3d(sigma4, centre = mu_3D[[4]]), col = "red")
#new loglik calculation
loglik[k+1]<-mySum(pi1*(log(pi1)+log(matrix(dmvnorm(no_label_data,mu_3D[[1]],sigma1),nrow=4,ncol=200))))+
mySum(pi2*(log(pi2)+log(matrix(dmvnorm(no_label_data,mu_3D[[2]],sigma2),nrow=4,ncol=200)))) +
mySum(pi3*(log(pi3)+log(matrix(dmvnorm(no_label_data,mu_3D[[3]],sigma3),nrow=4,ncol=200)))) +
mySum(pi4*(log(pi4)+log(matrix(dmvnorm(no_label_data,mu_3D[[4]],sigma4),nrow=4,ncol=200))))
k<-k+1
}
# Comparison with library implementation of EM
# library(mixtools)
# gm<-mvnormalmixEM(x,k=2,epsilon=1e-04)  #multivariate normal distribution EM
#                                         #normalmixEM is only for univariate normal
# gm$lambda
# gm$mu
# gm$sigma
# gm$loglik
# plot(gm, which=2)
#
# (head(gm$posterior))
# pred<-apply(gm$posterior, 1, function(row) which.max(row))
# (confusionMatrix[1,1]+confusionMatrix[2,2])/1000 # accuracy
# (confusionMatrix[1,2]+confusionMatrix[2,1])/1000 # error rate
